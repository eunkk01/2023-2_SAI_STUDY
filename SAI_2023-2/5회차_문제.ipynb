{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["EW8vHzGy6DLv","2-VwHqKd6cvB"],"authorship_tag":"ABX9TyMexA9H3AqkdUOgjWz5sf/2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 이론문제 1\n","\n","<aside>\n","📢 맞는 문장은 O, 틀린 문장은 X로 표시하고 틀린 문장은 올바르게 고쳐주세요. (5점)\n","\n","</aside>\n","\n","1. **다음 코드의 출력 값은 tensor([7., 8.])이다. (1점)**\n","    \n","    ```python\n","    t = torch.FloatTensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n","    print(t.max(dim=0)[1])\n","    ```\n","    \n","    답: X, tensor([3, 3])\n","    \n","2. **다음 코드의 출력 값은 torch.Size([1, 2, 3])이다. (1점)**\n","    \n","    ```python\n","    t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n","    print(t.unsqueeze(dim=1).shape)\n","    ```\n","    \n","    답: X, torch.Size([2, 1, 3])\n","    \n","3. **cost function을 최소화하기 위해서 기울기가 음수일 때는 W가 작아져야 하고, 기울기가 양수일 때는 W가 커져야 한다. (1점)**\n","    \n","    ```\n","    H(x) = Wx + b    \n","    cost(W) = {1\\over m} \\sum_{i=1}^{m} (H(x^{(i)}) - y^{(i)})^2\n","    ```\n","\n","    답: X, 기울기가 음수일 때 W를 증가시켜야 하고, 양수일 때 감소시켜야 한다.\n","    \n","4. **Multivariable Linear regression에서 x가 많은 정보를 가지고 있을 때 Hypothesis Function이 너무 복잡해지는 것을 방지하고자 matmul() 함수를 사용한다. (1점)**\n","    \n","    답: O\n","    \n","5. **많은 양의 데이터를 Minibatch라는 작은 양의 데이터로 나누어 학습한다면, 모든 데이터의 cost를 다 계산한 후에 경사 하강법을 진행하기 때문에 컴퓨터의 무리를 덜 수 있다. (1점)**\n","    \n","    답:X, 모든X"],"metadata":{"id":"x3PIR9DN5dv9"}},{"cell_type":"markdown","source":["# 이론문제 2\n","\n","<aside>\n","📢 **아래의 문제에 답하고, 틀렸다면 틀린 이유에 대해 서술하시오.**\n","\n","</aside>\n","\n","1. 단층 퍼셉트론으로 XOR 문제를 해결할 수 있다. (X, 다층 퍼셉트론으로 해결 가능)\n","2. Sigmoid Function을 사용하는 여러 개의 layer가 쌓였을 때  Vanishing Gradient 현상이 일어나 문제가 발생한다. (O)\n","3. RBM을 이용한 weight 초기화 방법보다 간단하게 weight를 초기화 할 수 있는 대표적인 방법 2가지를 쓰시오. (단답형)\n","\n","    Xavier, He\n","\n","4. linear1에서 588개의 노드 사용하려고 한다. drop_prob값을 구하시오. (단답형)\n","\n","    ```python\n","    linear1 = torch.nn.Linear(784, 512, bias=True)\n","    .\n","    .\n","    .\n","    dropout = torch.nn.Dropout(p=drop_prob)\n","    ```\n","    \n","    0.25\n","\n","5. 각 layer마다 Normalization하여 균형된 분포를 만들어주는 것을 Batch Normalization이라 한다.  Batch Normalization을 사용함으로써 해결할 수 있는 문제점을 한 가지만 쓰시오. (단답형)\n","\n","    학습 과정에서 층 별로 입력 데이터 분포가 달라지는 현상인 내부 공변량 변화를 해결할 수 있음.\n"],"metadata":{"id":"wBB-vKkS5sY_"}},{"cell_type":"markdown","source":["# 실습문제 1"],"metadata":{"id":"EW8vHzGy6DLv"}},{"cell_type":"markdown","source":["(1) 파이토치에서는 특정 함수를 통해 일반곱과 행렬곱을 계산할 수 있습니다. 빈칸을 모두 채워주세요! (1점)"],"metadata":{"id":"L3uvL95-6Fl9"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UaAlup75OsA","executionInfo":{"status":"ok","timestamp":1696846749856,"user_tz":-540,"elapsed":8,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"6d7c0006-3a83-4d4c-87a1-03b4f7fe7448"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of Matrix 1:  torch.Size([3, 3])\n","Shape of Matrix 2:  torch.Size([3, 1])\n","일반곱 tensor([[ 1.,  2.,  3.],\n","        [ 8., 10., 12.],\n","        [21., 24., 27.]])\n","행렬곱 tensor([[14.],\n","        [32.],\n","        [50.]])\n"]}],"source":["import torch\n","\n","# 일반적인 곱셈과 행렬곱\n","\n","m1 = torch.FloatTensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","m2 = torch.FloatTensor([[1], [2], [3]])\n","\n","print('Shape of Matrix 1: ', m1.shape) # 3 x 3\n","print('Shape of Matrix 2: ', m2.shape) # 3 x 1\n","\n","print('일반곱', m1*m2) # 3 x 33\n","print('행렬곱', m1@m2) # 3 x 1"]},{"cell_type":"markdown","source":["(2) 파이토치에서는 view를 통해 tensor의 크기를 변환할 수 있습니다. 빈칸을 모두 채워주세요! (1점)"],"metadata":{"id":"OBsTv1FE6IkR"}},{"cell_type":"code","source":["import numpy as np\n","\n","t = np.array([[[0, 1, 2],\n","               [3, 4, 5]],\n","              [[6, 7, 8],\n","               [9, 10, 11]]])\n","\n","ft = torch.FloatTensor(t)\n","\n","print(ft.shape)  # torch.Size([2, 2, 3])\n","\n","print(ft.view(6, 2)) # ft를 6 x 2로 변환하세요!\n","\n","print(ft.view(3, 2, 2)) # 3 x 2 x 2로 변환하세요!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZ9x0E7v59oY","executionInfo":{"status":"ok","timestamp":1696846896060,"user_tz":-540,"elapsed":2,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"553fd553-4060-4eec-b486-532223b7b04a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2, 3])\n","tensor([[ 0.,  1.],\n","        [ 2.,  3.],\n","        [ 4.,  5.],\n","        [ 6.,  7.],\n","        [ 8.,  9.],\n","        [10., 11.]])\n","tensor([[[ 0.,  1.],\n","         [ 2.,  3.]],\n","\n","        [[ 4.,  5.],\n","         [ 6.,  7.]],\n","\n","        [[ 8.,  9.],\n","         [10., 11.]]])\n"]}]},{"cell_type":"markdown","source":["(3) nn.Module을 통한 Linear Regression에 대해 복습해보아요! 아래의 비어있는 부분을 채워서 코드가 제대로 작동할 수 있도록 해주세요. (개당 1점, 총 3점)"],"metadata":{"id":"zznxTR0K6O44"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# For reproducibility\n","torch.manual_seed(42)\n","\n","# 예시 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","\n","# 모델 초기화\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","model = LinearRegressionModel()\n","\n","# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","nb_epochs = 1000\n","\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","\n","\t# 역전파를 이용한 gradient 계산\n","    cost.backward()\n","\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRoETYq059tG","executionInfo":{"status":"ok","timestamp":1696847134321,"user_tz":-540,"elapsed":984,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"57c90723-8ee7-4522-8a63-a38bd8439def"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 W: 0.753, b: 0.823 Cost: 0.165903\n","Epoch  100/1000 W: 0.730, b: 0.613 Cost: 0.054240\n","Epoch  200/1000 W: 0.788, b: 0.482 Cost: 0.033517\n","Epoch  300/1000 W: 0.833, b: 0.379 Cost: 0.020712\n","Epoch  400/1000 W: 0.869, b: 0.298 Cost: 0.012798\n","Epoch  500/1000 W: 0.897, b: 0.234 Cost: 0.007909\n","Epoch  600/1000 W: 0.919, b: 0.184 Cost: 0.004887\n","Epoch  700/1000 W: 0.936, b: 0.145 Cost: 0.003020\n","Epoch  800/1000 W: 0.950, b: 0.114 Cost: 0.001866\n","Epoch  900/1000 W: 0.961, b: 0.089 Cost: 0.001153\n","Epoch 1000/1000 W: 0.969, b: 0.070 Cost: 0.000713\n"]}]},{"cell_type":"markdown","source":["(4) 건강검진 데이터에서 흡연여부, 음주여부, 키 3가지 특징값을 가지고 성별(남자 = 1, 여자 = 2)을 유추하는 모델을 만들어 학습해봅시다. \"\"에 해당하는 부분만 채워주시면 됩니다. (총 5점)"],"metadata":{"id":"kcAmHi9K6Txm"}},{"cell_type":"code","source":["file = open('health_screenings_2020_1000ea.csv')\n","data = pd.read_csv(file)\n","data.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"G5NeNlCi-m4Q","executionInfo":{"status":"ok","timestamp":1696847892336,"user_tz":-540,"elapsed":6,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"1ad10447-0ddf-43be-b215-9d9ebfe202d9"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   year  city_code  gender  age_code  height  weight  waist  eye_left  \\\n","0  2020         36       1         9     165      60   72.1       1.2   \n","1  2020         27       2        13     150      65   81.0       0.8   \n","\n","   eye_right  hear_left  ...  serum   AST   ALT   GTP  smoking  drinking  \\\n","0        1.5          1  ...    1.1  21.0  27.0  21.0        1         0   \n","1        0.8          1  ...    0.5  18.0  15.0  15.0        1         0   \n","\n","   oral_check  dental_caries  tartar   open_date  \n","0           0            NaN     NaN  2021-12-29  \n","1           0            NaN     NaN  2021-12-29  \n","\n","[2 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-ce1462ee-3d4a-4878-93c6-28e6e221e219\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>city_code</th>\n","      <th>gender</th>\n","      <th>age_code</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>waist</th>\n","      <th>eye_left</th>\n","      <th>eye_right</th>\n","      <th>hear_left</th>\n","      <th>...</th>\n","      <th>serum</th>\n","      <th>AST</th>\n","      <th>ALT</th>\n","      <th>GTP</th>\n","      <th>smoking</th>\n","      <th>drinking</th>\n","      <th>oral_check</th>\n","      <th>dental_caries</th>\n","      <th>tartar</th>\n","      <th>open_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020</td>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>165</td>\n","      <td>60</td>\n","      <td>72.1</td>\n","      <td>1.2</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1.1</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>21.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2021-12-29</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020</td>\n","      <td>27</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>150</td>\n","      <td>65</td>\n","      <td>81.0</td>\n","      <td>0.8</td>\n","      <td>0.8</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0.5</td>\n","      <td>18.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2021-12-29</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce1462ee-3d4a-4878-93c6-28e6e221e219')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ce1462ee-3d4a-4878-93c6-28e6e221e219 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ce1462ee-3d4a-4878-93c6-28e6e221e219');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f94cd17f-91ed-467d-89aa-57833dbb10b6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f94cd17f-91ed-467d-89aa-57833dbb10b6')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f94cd17f-91ed-467d-89aa-57833dbb10b6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","\n","# health_screenings_2020_1000ea.csv파일을 업로드 합니다.\n","\n","# from google.colab import files\n","# uploaded = files.upload()\n","\n","file = open('health_screenings_2020_1000ea.csv')\n","data = pd.read_csv(file)\n","data\n","\n","\"\"\"\n","smoking이 1, 2인 경우 0(흡연 X), smoking이 3인 경우 1(흡연 O)로 데이터를 변경해줍니다.\n","\"\"\"\n","# 1점\n","data.loc[data['smoking'] < 3, 'smoking']=0\n","data.loc[data['smoking'] == 3, 'smoking']=1\n","\n","\"\"\"\n","'smoking', 'drinking', 'height' 3개의 특징만을 추출해서 train_x 변수에 삽입합니다.\n","'gender' 값을 train_y 변수에 삽입합니다.\n","\"\"\"\n","# 1점\n","train_x = data[['smoking', 'drinking', 'height']]\n","train_y = data['gender']\n","\n","\n","train_x = train_x.values.tolist()\n","train_y = train_y.values.tolist()\n","print(train_x)\n","print(train_y)\n","\n","x_train = torch.FloatTensor(train_x)\n","y_train = torch.FloatTensor(train_y).view(len(train_y), -1)\n","\n","\"\"\"\n","특징값들 사이에 편차가 심하기 때문에 x_train을 정규화 해줍니다.\n","\"\"\"\n","# Standardization\n","mu = x_train.mean(dim=0)\n","sigma = x_train.std(dim=0)\n","\n","x_train = (x_train - mu) / sigma\n","x_train\n","\n","class MultivariateLinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(3, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","model = MultivariateLinearRegressionModel()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","nb_epochs = 1000\n","\n","\n","#mse_loss를 사용해서 학습을 진행해 봅시다.\n","\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f} '.format(\n","            epoch, nb_epochs, cost.item(),\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwcKwz1_59xG","executionInfo":{"status":"ok","timestamp":1696847894605,"user_tz":-540,"elapsed":9,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"eb815026-50ce-40cf-f352-dbb692cab62f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n","[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n","Epoch    0/1000 Cost: 0.100138 \n","Epoch  100/1000 Cost: 0.000000 \n","Epoch  200/1000 Cost: 0.000000 \n","Epoch  300/1000 Cost: 0.000000 \n","Epoch  400/1000 Cost: 0.000000 \n","Epoch  500/1000 Cost: 0.000000 \n","Epoch  600/1000 Cost: 0.000000 \n","Epoch  700/1000 Cost: 0.000000 \n","Epoch  800/1000 Cost: 0.000000 \n","Epoch  900/1000 Cost: 0.000000 \n","Epoch 1000/1000 Cost: 0.000000 \n"]}]},{"cell_type":"markdown","source":["# 실습문제 2\n","\n","민석이는 손글씨 인식 프로그램 개발을 위해 우선 MNIST 데이터셋을 기계학습시키는 과정을 거치려고 한다. 아직은 실력이 부족해 학습의 정확도가 70%에 불과한데, 파이토치에 대해 잘 아는 우리가 그동안 배운 방법으로 민석이를 도와 정확도를 96%까지 올려보도록 하자. (정확도도 첨부해주세요!)"],"metadata":{"id":"2-VwHqKd6cvB"}},{"cell_type":"code","source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import random\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","random.seed(777)\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","# parameters\n","learning_rate = 0.001\n","training_epochs = 20\n","batch_size = 100\n","drop_out = 0.3\n","\n","# MNIST dataset\n","mnist_train = dsets.MNIST(root='MNIST_data/',\n","                          train=True,\n","                          transform=transforms.ToTensor(),\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/',\n","                         train=False,\n","                         transform=transforms.ToTensor(),\n","                         download=True)\n","\n","# dataset loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)\n","\n","# layer\n","linear1 = torch.nn.Linear(784, 512, bias=True)\n","linear2 = torch.nn.Linear(512, 512, bias=True)\n","linear3 = torch.nn.Linear(512, 512, bias=True)\n","linear4 = torch.nn.Linear(512, 512, bias=True)\n","linear5 = torch.nn.Linear(512, 10, bias=True)\n","\n","relu = torch.nn.ReLU()\n","dropout = torch.nn.Dropout(p=drop_prob)\n","\n","# model\n","model = torch.nn.Sequential(linear1, relu, dropout,\n","                            linear2, relu, dropout,\n","                            linear3, relu, dropout,\n","                            linear4, relu, dropout,\n","                            linear5).to(device)\n","\n","# define cost/loss & optimizer\n","criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","total_batch = len(data_loader)\n","model.eval()\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","\n","    for X, Y in data_loader:\n","        # reshape input image into [batch_size by 784]\n","        # label is not one-hot encoded\n","        X = X.view(-1, 28 * 28).to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n","\n","print('Learning finished')\n","\n","# Test model and check accuracy\n","with torch.no_grad():\n","    model.train()\n","\n","    # Test the model using test sets\n","    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n","    Y_test = mnist_test.test_labels.to(device)\n","\n","    prediction = model(X_test)\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test\n","    accuracy = correct_prediction.float().mean()\n","    print('Accuracy:', accuracy.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GUHKG2N6d9b","executionInfo":{"status":"ok","timestamp":1696849911479,"user_tz":-540,"elapsed":497117,"user":{"displayName":"고은경","userId":"10765015356207281747"}},"outputId":"5a322d7c-39c2-4613-871e-d7c148108437"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0001 cost = 0.431372643\n","Epoch: 0002 cost = 0.263876289\n","Epoch: 0003 cost = 0.218902618\n","Epoch: 0004 cost = 0.209492534\n","Epoch: 0005 cost = 0.178373918\n","Epoch: 0006 cost = 0.181518257\n","Epoch: 0007 cost = 0.169523954\n","Epoch: 0008 cost = 0.178160027\n","Epoch: 0009 cost = 0.167264298\n","Epoch: 0010 cost = 0.153036028\n","Learning finished\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n","  warnings.warn(\"test_data has been renamed data\")\n","/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n","  warnings.warn(\"test_labels has been renamed targets\")\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9456999897956848\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"S_S9f-gSBw5A"},"execution_count":null,"outputs":[]}]}